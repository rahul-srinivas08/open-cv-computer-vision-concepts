{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f1d26f8562da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mframe_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mgood_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"slow_traffic_small.mp4\")\n",
    "\n",
    "feature_params = dict( maxCorners = 100,qualityLevel = 0.3,minDistance = 7,blockSize = 7 )\n",
    "lk_params = dict(winSize  = (15,15),maxLevel = 2,criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"red_panda.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Gray panda\", gray_image)\n",
    "cv2.imshow(\"Red panda\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    \n",
    "    # Frames are read by intervals of 1 millisecond. The \n",
    "    # programs breaks out of the while loop when the \n",
    "    # user presses the 'q' key \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(\"red_panda.jpg\")\n",
    "shape = image.shape\n",
    "blue = (255, 0, 0)\n",
    "red = (0, 0, 255)\n",
    "green = (0, 255, 0)\n",
    "violet = (180, 0, 180)\n",
    "yellow = (0, 180, 180)\n",
    "white = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[162, 140, 134],\n",
       "        [232, 224, 201],\n",
       "        [255, 255, 242],\n",
       "        ...,\n",
       "        [165, 214, 246],\n",
       "        [174, 224, 244],\n",
       "        [193, 244, 254]],\n",
       "\n",
       "       [[222, 205, 192],\n",
       "        [255, 255, 249],\n",
       "        [246, 253, 248],\n",
       "        ...,\n",
       "        [163, 207, 254],\n",
       "        [178, 223, 255],\n",
       "        [195, 240, 255]],\n",
       "\n",
       "       [[255, 251, 242],\n",
       "        [248, 255, 255],\n",
       "        [192, 191, 255],\n",
       "        ...,\n",
       "        [160, 198, 255],\n",
       "        [170, 209, 255],\n",
       "        [174, 213, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[110, 109, 113],\n",
       "        [110, 109, 113],\n",
       "        [112, 111, 115],\n",
       "        ...,\n",
       "        [ 18,  12,  13],\n",
       "        [ 17,  11,  12],\n",
       "        [ 17,  11,  12]],\n",
       "\n",
       "       [[102, 101, 105],\n",
       "        [101, 100, 104],\n",
       "        [100,  99, 103],\n",
       "        ...,\n",
       "        [ 16,  10,  11],\n",
       "        [ 16,  10,  11],\n",
       "        [ 17,  11,  12]],\n",
       "\n",
       "       [[ 92,  91,  95],\n",
       "        [ 90,  89,  93],\n",
       "        [ 87,  86,  90],\n",
       "        ...,\n",
       "        [ 13,   7,   8],\n",
       "        [ 13,   7,   8],\n",
       "        [ 14,   8,   9]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.line(image, (50, 30), (450, 35), blue, thickness=5)\n",
    "cv2.circle(image, (240, 205), 23, red, -1)\n",
    "cv2.rectangle(image, (50, 60), (450, 95), green, -1)\n",
    "cv2.ellipse(image, (250, 150), (80, 20), 5, 0, 360, violet, -1)\n",
    "points = np.array([[[140, 230], [380, 230], [320, 250], [250, 280]]], np.int32)\n",
    "cv2.polylines(image, [points], True, yellow, thickness=3)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(image, \"Panda\", (20, 180), font, 4, white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"red panda\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"flag.png\")\n",
    "rows, cols, ch = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = image[100: 280, 150: 320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 255   0]\n"
     ]
    }
   ],
   "source": [
    "print(image[175, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[250, 180] = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"flag\", image)\n",
    "cv2.imshow(\"Roi\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread(\"car-300x169.jpg\")\n",
    "image2 = cv2.imread(\"road-300x169.jpg\")\n",
    "sum1 = cv2.add(image1, image2)\n",
    "weighted = cv2.addWeighted(image1, 0.3, image2, 0.7, 0)\n",
    "img2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, mask = cv2.threshold(img2_gray, 240, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "road = cv2.bitwise_and(img1, img1, mask=mask)\n",
    "car = cv2.bitwise_and(img2, img2, mask=mask_inv)\n",
    "result = cv2.add(road, car)\n",
    "\n",
    "cv2.imshow(\"weighted\", weighted)\n",
    "cv2.imshow(\"sum1\", sum1)\n",
    "cv2.imshow(\"image1\", image1)\n",
    "cv2.imshow(\"image2\", image2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"road-300x169.jpg\")\n",
    "img2 = cv2.imread(\"car-300x169.jpg\")\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, mask = cv2.threshold(img2_gray, 240, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "road = cv2.bitwise_and(img1, img1, mask=mask)\n",
    "car = cv2.bitwise_and(img2, img2, mask=mask_inv)\n",
    "result = cv2.add(road, car)\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imshow(\"mask_inv\", mask_inv)\n",
    "cv2.imshow(\"road background\", road)\n",
    "cv2.imshow(\"car no background\", car)\n",
    "cv2.imshow(\"result\", result)\n",
    "#cv2.imshow(\"road background\", road)\n",
    "#cv2.imshow(\"car no background\", car)\n",
    "#cv2.imshow(\"mask\", mask)\n",
    "#cv2.imshow(\"mask inverse\", mask_inv)\n",
    "#cv2.imshow(\"result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"drawing_1.png\")\n",
    "img2 = cv2.imread(\"drawing_2.png\")\n",
    "\n",
    "bit_and = cv2.bitwise_and(img2, img1)\n",
    "bit_or = cv2.bitwise_or(img2, img1)\n",
    "bit_xor = cv2.bitwise_xor(img1, img2)\n",
    "bit_not = cv2.bitwise_not(img1)\n",
    "bit_not2 = cv2.bitwise_not(img2)\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "\n",
    "cv2.imshow(\"bit_and\", bit_and)\n",
    "cv2.imshow(\"bit_or\", bit_or)\n",
    "cv2.imshow(\"bit_xor\", bit_xor)\n",
    "cv2.imshow(\"bit_not\", bit_not)\n",
    "cv2.imshow(\"bit_not2\", bit_not2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"frame\")\n",
    "cv2.createTrackbar(\"test\", \"frame\", 50, 500, nothing)\n",
    "cv2.createTrackbar(\"color/gray\", \"frame\", 0, 1, nothing)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    test = cv2.getTrackbarPos(\"test\", \"frame\")\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    cv2.putText(frame, str(test), (50, 150), font, 4, (0, 0, 255))\n",
    "    \n",
    "    s = cv2.getTrackbarPos(\"color/gray\", \"frame\")\n",
    "    if s == 0:\n",
    "        pass\n",
    "    else:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "\n",
    "cv2.createTrackbar(\"L – H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L – S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L – V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U – H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U – S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U – V\", \"Trackbars\", 255, 255, nothing)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    l_h = cv2.getTrackbarPos(\"L – H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L – S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L – V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U – H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U – S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U – V\", \"Trackbars\")\n",
    "    \n",
    "    lower_blue = np.array([l_h, l_s, l_v])\n",
    "    upper_blue = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"result\", result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"black_to_white.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, threshold_binary = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "_, threshold_binary_inv = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "_, threshold_trunc = cv2.threshold(img, 128, 255, cv2.THRESH_TRUNC)\n",
    "_, threshold_to_zero = cv2.threshold(img, 12, 255, cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"th binary\", threshold_binary)\n",
    "cv2.imshow(\"th binary inv\", threshold_binary_inv)\n",
    "cv2.imshow(\"th trunc\", threshold_trunc)\n",
    "cv2.imshow(\"th to zero\", threshold_to_zero)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "img = cv2.imread(\"red_panda.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.createTrackbar(\"Threshold value\", \"Image\", 128, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    value_threshold = cv2.getTrackbarPos(\"Threshold value\", \"Image\")\n",
    "    _, threshold_binary = cv2.threshold(img, value_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, threshold_binary_inv = cv2.threshold(img, value_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    _, threshold_trunc = cv2.threshold(img, value_threshold, 255, cv2.THRESH_TRUNC)\n",
    "    _, threshold_to_zero = cv2.threshold(img, value_threshold, 255, cv2.THRESH_TOZERO)\n",
    "    _, threshold_to_zero_inv = cv2.threshold(img, value_threshold, 255, cv2.THRESH_TOZERO_INV)\n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.imshow(\"th binary\", threshold_binary)\n",
    "    cv2.imshow(\"th binary inv\", threshold_binary_inv)\n",
    "    cv2.imshow(\"th trunc\", threshold_trunc)\n",
    "    cv2.imshow(\"th to zero\", threshold_to_zero)\n",
    "    cv2.imshow(\"th to zero inv\", threshold_to_zero_inv)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"sea_beach.jpg\")\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"b\", b)\n",
    "cv2.imshow(\"g\", g)\n",
    "cv2.imshow(\"r\", r)\n",
    "\n",
    "plt.hist(b.ravel(), 256, [0, 256])\n",
    "plt.hist(g.ravel(), 256, [0, 256])\n",
    "plt.hist(r.ravel(), 256, [0, 256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height:  300\n",
      "Width:  500\n",
      "(150, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"red_panda.jpg\")\n",
    "rows, cols, ch = img.shape\n",
    "\n",
    "print(\"Height: \", rows)\n",
    "print(\"Width: \", cols)\n",
    "\n",
    "scaled_img = cv2.resize(img, None, fx=1/2, fy=1/2)\n",
    "print(scaled_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_t = np.float32([[1, 0, -100], [0, 1, -30]])\n",
    "translated_img = cv2.warpAffine(img, matrix_t, (cols, rows))\n",
    "\n",
    "matrix_r = cv2.getRotationMatrix2D((cols/2, rows/2), 90, 0.5)\n",
    "rotated_img = cv2.warpAffine(img, matrix_r, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.imshow(\"Scaled image\", scaled_img)\n",
    "cv2.imshow(\"Translated image\", translated_img)\n",
    "cv2.imshow(\"Rotated image\", rotated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"grid.jpg\")\n",
    "rows, cols, ch = img.shape\n",
    "\n",
    "cv2.circle(img, (83, 90), 5, (0, 0, 255), -1)\n",
    "cv2.circle(img, (447, 90), 5, (0, 0, 255), -1)\n",
    "cv2.circle(img, (83, 472), 5, (0, 0, 255), -1)\n",
    "\n",
    "pts1 = np.float32([[83, 90], [447, 90], [83, 472]])\n",
    "pts2 = np.float32([[0, 0], [447, 90], [150, 472]])\n",
    "\n",
    "matrix = cv2.getAffineTransform(pts1, pts2)\n",
    "result = cv2.warpAffine(img, matrix, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Affine transformation\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"book_page.jpg\")\n",
    "\n",
    "_, threshold = cv2.threshold(img, 155, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "mean_c = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 12)\n",
    "gaus = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 12)\n",
    "cv2.imshow(\"Img\", img)\n",
    "cv2.imshow(\"Binary threshold\", threshold)\n",
    "cv2.imshow(\"Mean C\", mean_c)\n",
    "cv2.imshow(\"Gaussian\", gaus)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"early_1800.jpg\")\n",
    "\n",
    "averaging = cv2.blur(img, (21, 21))\n",
    "gaussian = cv2.GaussianBlur(img, (21, 21), 3)\n",
    "median = cv2.medianBlur(img, 5)\n",
    "bilateral = cv2.bilateralFilter(img, 9, 350, 350)\n",
    "\n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.imshow(\"Averaging\", averaging)\n",
    "cv2.imshow(\"Gaussian\", gaussian)\n",
    "cv2.imshow(\"Median\", median)\n",
    "cv2.imshow(\"Bilateral\", bilateral)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"balls.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(mask, kernel)\n",
    "erosion = cv2.erode(mask, kernel, iterations=6)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Dilation\", dilation)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"white_panda.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.GaussianBlur(img, (11, 11), 0)\n",
    "\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=5)\n",
    "\n",
    "canny = cv2.Canny(img, 100, 150)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Sobelx\", sobelx)\n",
    "cv2.imshow(\"Sobely\", sobely)\n",
    "cv2.imshow(\"Laplacian\", laplacian)\n",
    "cv2.imshow(\"Canny\", canny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    laplacian = cv2.Laplacian(blurred_frame, cv2.CV_64F)\n",
    "    canny = cv2.Canny(blurred_frame, 100, 150)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Laplacian\", laplacian)\n",
    "    cv2.imshow(\"Canny\", canny)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c702cf46cf34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mupper_blue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower_blue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_blue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_NONE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcontour\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([38, 86, 0])\n",
    "    upper_blue = np.array([121, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    _, contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(frame, contour, -1, (0, 255, 0), 1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"simpsons.jpg\")\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread(\"barts_face.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "result = cv2.matchTemplate(gray_img, template, cv2.TM_CCOEFF_NORMED)\n",
    "loc = np.where(result >= 0.4)\n",
    "\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "template = cv2.imread(\"barts_face.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    res = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    loc = np.where(res >= 0.7)\n",
    "\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.rectangle(frame, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 3)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lines.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 75, 150)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 75, 150)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "video = cv2.VideoCapture(\"road_car_view.mp4\")\n",
    "while True:\n",
    "    ret, orig_frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(\"road_car_view.mp4\")\n",
    "        continue\n",
    "    frame = cv2.GaussianBlur(orig_frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    low_yellow = np.array([18, 94, 140])\n",
    "    up_yellow = np.array([48, 255, 255])\n",
    "    mask = cv2.inRange(hsv, low_yellow, up_yellow)\n",
    "    edges = cv2.Canny(mask, 75, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"edges\", edges)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.createTrackbar(\"quality\", \"Frame\", 1, 100, nothing)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    quality = cv2.getTrackbarPos(\"quality\", \"Frame\")\n",
    "    quality = quality / 100 if quality > 0 else 0.01\n",
    "    corners = cv2.goodFeaturesToTrack(gray, 100, quality, 20)\n",
    "\n",
    "    if corners is not None:\n",
    "        corners = np.int0(corners)\n",
    "\n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"hand.jpg\")\n",
    "\n",
    "# Gaussian Pyramid\n",
    "layer = img.copy()\n",
    "gaussian_pyramid = [layer]\n",
    "for i in range(6):\n",
    "    layer = cv2.pyrDown(layer)\n",
    "    gaussian_pyramid.append(layer)\n",
    "\n",
    "# Laplacian Pyramid\n",
    "layer = gaussian_pyramid[5]\n",
    "cv2.imshow(\"6\", layer)\n",
    "laplacian_pyramid = [layer]\n",
    "for i in range(5, 0, -1):\n",
    "    size = (gaussian_pyramid[i-1].shape[1], gaussian_pyramid[i-1].shape[0])\n",
    "    gaussian_expanded = cv2.pyrUp(gaussian_pyramid[i], dstsize=size)\n",
    "    laplacian = cv2.subtract(gaussian_pyramid[i-1], gaussian_expanded)\n",
    "    laplacian_pyramid.append(laplacian)\n",
    "    cv2.imshow(str(i), laplacian)\n",
    "\n",
    "reconstructed_image = laplacian_pyramid[0]\n",
    "for i in range(1, 6):\n",
    "    size = (laplacian_pyramid[i].shape[1], laplacian_pyramid[i].shape[0])\n",
    "    reconstructed_image = cv2.pyrUp(reconstructed_image, dstsize=size)\n",
    "    reconstructed_image = cv2.add(reconstructed_image, laplacian_pyramid[i])\n",
    "    cv2.imshow(str(i), reconstructed_image)\n",
    "    \n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"the_book_thief.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"me_holding_book.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# ORB Detector\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# Brute Force Matching\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "matching_result = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None, flags=2)\n",
    "\n",
    "cv2.imshow(\"Img1\", img1)\n",
    "cv2.imshow(\"Img2\", img2)\n",
    "cv2.imshow(\"Matching result\", matching_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left click\n",
      "151 186\n",
      "Left click\n",
      "2 2\n",
      "Left click\n",
      "633 477\n"
     ]
    }
   ],
   "source": [
    "def mouse_drawing(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Left click\")\n",
    "        print(x,y)\n",
    "        circles.append((x, y))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", mouse_drawing)\n",
    "\n",
    "circles = []\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    for center_position in circles:\n",
    "        cv2.circle(frame, center_position, 5, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "original_image = cv2.imread(\"goalkeeper.jpg\")\n",
    "hsv_original = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "roi = cv2.imread(\"pitch_ground.jpg\")\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hue, saturation, value = cv2.split(hsv_roi)\n",
    "\n",
    "# Histogram ROI\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "mask = cv2.calcBackProject([hsv_original], [0, 1], roi_hist, [0, 180, 0, 256], 1)\n",
    "\n",
    "# Filtering remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "mask = cv2.filter2D(mask, -1, kernel)\n",
    "_, mask = cv2.threshold(mask, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "mask = cv2.merge((mask, mask, mask))\n",
    "result = cv2.bitwise_and(original_image, mask)\n",
    "\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Original image\", original_image)\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.imshow(\"Roi\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9e8f040910de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcBackProject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhsv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m180\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"mouthwash.avi\")\n",
    "\n",
    "_, first_frame = video.read()\n",
    "x = 300\n",
    "y = 305\n",
    "width = 100\n",
    "height = 115\n",
    "roi = first_frame[y: y + height, x: x + width]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "term_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "cv2.imshow(\"roi\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "while True:\n",
    "    _, frame = video.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "    _, track_window = cv2.meanShift(mask, (x, y, width, height), term_criteria)\n",
    "    x, y, w, h = track_window\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)q\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"gray_cover.jpg\")\n",
    "roi = img[252: 395, 354: 455]\n",
    "x = 354\n",
    "y = 252\n",
    "width = 455-x\n",
    "height = 395 -y\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "term_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "    ret, track_window = cv2.CamShift(mask, (x, y, width, height), term_criteria)\n",
    "\n",
    "    pts = cv2.boxPoints(ret)\n",
    "    pts = np.int0(pts)\n",
    "    cv2.polylines(frame, [pts], True, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create old frame\n",
    "_, frame = cap.read()\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Lucas kanade params\n",
    "lk_params = dict(winSize = (15, 15),\n",
    "maxLevel = 4,\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Mouse function\n",
    "def select_point(event, x, y, flags, params):\n",
    "    global point, point_selected, old_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = (x, y)\n",
    "        point_selected = True\n",
    "        old_points = np.array([[x, y]], dtype=np.float32)\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", select_point)\n",
    "\n",
    "point_selected = False\n",
    "point = ()\n",
    "old_points = np.array([[]])\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if point_selected is True:\n",
    "        cv2.circle(frame, point, 5, (0, 0, 255), 2)\n",
    "\n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, old_points, None, **lk_params)\n",
    "        old_gray = gray_frame.copy()\n",
    "        old_points = new_points\n",
    "\n",
    "        x, y = new_points.ravel()\n",
    "        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# The following frees up resources and \n",
    "# closes all windows \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(\"highway.mp4\")\n",
    "subtractor = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=True)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    mask = subtractor.apply(frame)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.ORB' object has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b3bd690d6c81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0morb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mORB_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mkp_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Feature matching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.ORB' object has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"ultimo_sopravvissuto.jpg\", cv2.IMREAD_GRAYSCALE)  # queryiamge\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Features\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    "# Feature matching\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # trainimage\n",
    "    kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)\n",
    "    matches = flann.knnMatch(desc_image, desc_grayframe, k=2)\n",
    "    good_points = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.6 * n.distance:\n",
    "            good_points.append(m)\n",
    "    # img3 = cv2.drawMatches(img, kp_image, grayframe, kp_grayframe, good_points, grayframe)\n",
    "    # Homography\n",
    "    if len(good_points) > 10:\n",
    "        query_pts = np.float32([kp_image[m.queryIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "        # Perspective transform\n",
    "        h, w = img.shape\n",
    "        pts = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        dst = cv2.perspectiveTransform(pts, matrix)\n",
    "        homography = cv2.polylines(frame, [np.int32(dst)], True, (255, 0, 0), 3)\n",
    "        cv2.imshow(\"Homography\", homography)\n",
    "    else:\n",
    "        cv2.imshow(\"Homography\", grayframe)\n",
    "    # cv2.imshow(\"Image\", img)\n",
    "    # cv2.imshow(\"grayFrame\", grayframe)\n",
    "    # cv2.imshow(\"img3\", img3)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as  np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "list_images = glob.iglob(\"letters/*\")\n",
    "\n",
    "for image_title in list_images:\n",
    "    img = cv2.imread(image_title, cv2.IMREAD_GRAYSCALE)\n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    magnitude_spectrum = np.asarray(magnitude_spectrum, dtype=np.uint8)\n",
    "    img_and_magnitude = np.concatenate((img, magnitude_spectrum), axis=1)\n",
    "\n",
    "    cv2.imshow(image_title, img_and_magnitude)\n",
    "    print(\"d\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [7.]\n",
      " [7.]\n",
      " [7.]\n",
      " [7.]\n",
      " [7.]\n",
      " [8.]\n",
      " [1.]\n",
      " [8.]\n",
      " [8.]\n",
      " [8.]\n",
      " [9.]\n",
      " [9.]\n",
      " [9.]\n",
      " [9.]\n",
      " [9.]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "digits = cv2.imread(\"digits.png\", cv2.IMREAD_GRAYSCALE)\n",
    "test_digits = cv2.imread(\"test_digits.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "rows = np.vsplit(digits, 50)\n",
    "cells = []\n",
    "for row in rows:\n",
    "    row_cells = np.hsplit(row, 50)\n",
    "    for cell in row_cells:\n",
    "        cell = cell.flatten()\n",
    "        cells.append(cell)\n",
    "cells = np.array(cells, dtype=np.float32)\n",
    "k = np.arange(10)\n",
    "cells_labels = np.repeat(k, 250)\n",
    "\n",
    "\n",
    "test_digits = np.vsplit(test_digits, 50)\n",
    "test_cells = []\n",
    "for d in test_digits:\n",
    "    d = d.flatten()\n",
    "    test_cells.append(d)\n",
    "test_cells = np.array(test_cells, dtype=np.float32)\n",
    "\n",
    "\n",
    "# KNN\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(cells, cv2.ml.ROW_SAMPLE, cells_labels)\n",
    "ret, result, neighbours, dist = knn.findNearest(test_cells, k=3)\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.createTrackbar(\"Neighbours\", \"Frame\", 5, 20, nothing)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    neighbours = cv2.getTrackbarPos(\"Neighbours\", \"Frame\")\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, neighbours)\n",
    "    for rect in faces:\n",
    "        (x, y, w, h) = rect\n",
    "        frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
